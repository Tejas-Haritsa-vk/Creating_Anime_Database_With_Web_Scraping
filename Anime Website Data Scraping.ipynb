{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anime Website Data Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing required libraries\n",
    "import urllib\n",
    "from urllib.request import Request, urlopen\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import re\n",
    "from string import ascii_uppercase\n",
    "import csv\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://www4.animeseries.io\" #initilizing base url\n",
    "url_template = \"https://www4.animeseries.io/search/character=special\" #initilizing url template for alphabetical search\n",
    "# https://www4.animeseries.io/search/character=special\n",
    "url = base_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ABCDEFGHIJKLMNOPQRSTUVWXYZ'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ascii_uppercase #viewing ascii_uppercase contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed special     \n",
      "Processed A     \n",
      "Processed B     \n",
      "Processed C     \n",
      "Processed D     \n",
      "Processed E     \n",
      "Processed F     \n",
      "Processed G     \n",
      "Processed H     \n",
      "Processed I     \n",
      "Processed J     \n",
      "Processed K     \n",
      "Processed L     \n",
      "Processed M     \n",
      "Processed N     \n",
      "Processed O     \n",
      "Processed P     \n",
      "Processed Q     \n",
      "Processed R     \n",
      "Processed S     \n",
      "Processed T     \n",
      "Processed U     \n",
      "Processed V     \n",
      "Processed W     \n",
      "Processed X     \n",
      "Processed Y     \n",
      "Processed Z     \n",
      "Web Scraping Complete\n",
      "Total Time Taken: 5989.001123666763s\n"
     ]
    }
   ],
   "source": [
    "#initializing empty list & dictionary\n",
    "Anime = []\n",
    "anime_dict={}\n",
    "\n",
    "#creating a list of charecters to loop through\n",
    "charecters = list(ascii_uppercase)\n",
    "charecters.insert(0,\"special\")\n",
    "\n",
    "main_start = time.time()\n",
    "\n",
    "for alphabet in charecters[:]:\n",
    "\n",
    "    print(\"\\rProcessing {}.\".format(alphabet),end='')\n",
    "    #substituting 'special' keyword with alphabet\n",
    "    url = re.sub('special',alphabet,url_template)\n",
    "    \n",
    "    url_link = Request(url, headers={'User-Agent': 'Mozilla/5.0'}) #requesting for url\n",
    "    url_page = urlopen(url_link).read() #reading url\n",
    "    url_html = bs(url_page, 'html.parser') #parsing html file using BeautifulSoup\n",
    "    \n",
    "    #getting all div's having class_='content_episode revent datagrild'\n",
    "    containers = url_html.find_all('div',class_='content_episode revent datagrild')\n",
    "    \n",
    "    \n",
    "    print(\"\\rProcessing {}..\".format(alphabet),end='')\n",
    "    \n",
    "    #looping through containers to extract more detailed info\n",
    "    for items in containers[:]:\n",
    "        \n",
    "        animes = items.find_all('div',class_ = \"name\")\n",
    "        html_links = items.find_all('a') #getting url of anime\n",
    "        \n",
    "        for i,anime in enumerate(animes[:]):\n",
    "            name=''\n",
    "            description=''\n",
    "            season=''\n",
    "            genre=''\n",
    "            new_url=''\n",
    "            status=''\n",
    "            episodes=''\n",
    "            status\n",
    "            initial_air_date=''\n",
    "            movie=''\n",
    "            sub=''\n",
    "            \n",
    "            \n",
    "            try:\n",
    "                title = anime.text#find('div',class_ = \"name\").text #getting name of anime\n",
    "                html_link = html_links[i].get('href') #getting url of anime\n",
    "\n",
    "                #Checking if Season in mentioned in title & extracting both name and season seperatly\n",
    "                if re.search(r\"Season [0-9]?\",title):\n",
    "                    name,season = re.split(r\"Season [0-9]?\",title)\n",
    "                elif re.search(r\"[0-9][a-z]+? Season\",title):\n",
    "                    name,season = re.split(r\"[0-9][a-z]+? Season\",title)\n",
    "                elif re.search(r\"[0-9][a-z][a-z]\",title):\n",
    "                    try:\n",
    "                        name,season = re.split(r\"[0-9]['nd','rd','th']+\",title)\n",
    "                    except:\n",
    "                        name = re.split(r\"[0-9]['nd','rd','th']+\",title)[0]\n",
    "                else:\n",
    "                    name = title\n",
    "\n",
    "                pattern = r\"^([0-9][a-z]+? Season | Season [0-9][a-z]+?\\s )$\"\n",
    "                season = re.search(pattern,title)\n",
    "\n",
    "                if not season:\n",
    "                    #print('here_not')\n",
    "                    pattern = r\"[0-9]['nd','rd','th']+\"\n",
    "                    season = re.search(pattern,title)\n",
    "\n",
    "                if season:\n",
    "                    pass\n",
    "                else:\n",
    "                    season = [\"Season 1\"]\n",
    "                \n",
    "                if 'Dub' in title or 'dub' in title:\n",
    "                    sub = 'Dub'\n",
    "                else:\n",
    "                    sub = 'Sub'\n",
    "                \n",
    "\n",
    "                #creating new_url to reroute to anime main page to extract more detatiled information such as:\n",
    "                #1. description\n",
    "                #2. status\n",
    "                #3. initial air date\n",
    "                #4. genre\n",
    "                #5. total number of episodes\n",
    "                new_url = main_url+html_link\n",
    "                new_url = new_url.replace('watch','anime')\n",
    "                \n",
    "                url_link = Request(new_url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "                url_page = urlopen(url_link).read()\n",
    "                url_html = bs(url_page, 'html.parser')\n",
    "\n",
    "                #getting div's with class_=\"main_body\"\n",
    "                containers = url_html.find_all('div',class_=\"main_body\")\n",
    "                #getting div's with class_=\"right\"\n",
    "                contents = containers[0].find_all('div',class_='right')\n",
    "\n",
    "\n",
    "                #extracting description of anime\n",
    "                description = contents[0].find_all('p')[0].text \n",
    "                #extracting status, initial air date, genre & total number of episodes of anime\n",
    "                temp=[]\n",
    "                genre=[]\n",
    "                for i in contents[0].find_all('a')[2:]:\n",
    "                    temp.append(i.text)\n",
    "\n",
    "                status,initial_air_date = temp[:2]\n",
    "                genre = temp[2:]\n",
    "                genre = ', '.join(genre)\n",
    "\n",
    "                containers = containers[0].find_all('div',class_='list_episode')\n",
    "                try:\n",
    "                    text = containers[0].find('span',class_='name').text\n",
    "                    text = re.search('Episode [0-9]+',text)\n",
    "                    episodes = re.search('[0-9]+',text[0])[0]\n",
    "                    if int(episodes) > 0 and int(episodes) < 2:\n",
    "                        movie = 'Movie'\n",
    "                    else:\n",
    "                        movie = 'Series'\n",
    "                except:\n",
    "                    episodes = 'None'\n",
    "                    movie = 'None'\n",
    "\n",
    "\n",
    "                print(\"\\rProcessing {}...\".format(alphabet),end='')\n",
    "\n",
    "                #adding all extracted information in Anime dict\n",
    "                anime_dict['Anime Title'] = name\n",
    "                anime_dict['Description'] = description\n",
    "                anime_dict['Current/Latest Season'] = season[0]\n",
    "                anime_dict['URL'] = new_url\n",
    "                anime_dict['Status'] = status\n",
    "                anime_dict['Initial Air Date'] = initial_air_date\n",
    "                anime_dict['Genre'] = genre\n",
    "                anime_dict['Episodes Aired'] = episodes\n",
    "                anime_dict['Series/Movie'] = movie\n",
    "                anime_dict['Sub/Dub'] = sub\n",
    "\n",
    "                new_dict = anime_dict.copy()\n",
    "\n",
    "                Anime.append(new_dict)\n",
    "                \n",
    "            except:\n",
    "\n",
    "                print(\"\\rProcessing {}...\".format(alphabet),end='')\n",
    "                \n",
    "                try:\n",
    "                    #adding all extracted information in Anime dict\n",
    "                    anime_dict['Anime Title'] = name\n",
    "                    anime_dict['Description'] = description\n",
    "                    anime_dict['Current/Latest Season'] = season[0]\n",
    "                    anime_dict['URL'] = new_url\n",
    "                    anime_dict['Status'] = status\n",
    "                    anime_dict['Initial Air Date'] = initial_air_date\n",
    "                    anime_dict['Genre'] = genre\n",
    "                    anime_dict['Episodes Aired'] = episodes\n",
    "                    anime_dict['Series/Movie'] = movie\n",
    "                    anime_dict['Sub/Dub'] = sub\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "                new_dict = anime_dict.copy()\n",
    "\n",
    "                Anime.append(new_dict)\n",
    "                \n",
    "#                 break\n",
    "    \n",
    "    print(\"\\rProcessed {}     \".format(alphabet))\n",
    "#     break\n",
    "    \n",
    "main_end = time.time() - main_start\n",
    "print('\\rWeb Scraping Complete')\n",
    "print(\"Total Time Taken: {}s\".format(main_end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Anime Title': 'Zutto Mae kara Suki deshita.: Kokuhaku Jikkou Iinkai - MOVIE',\n",
       " 'Description': 'Kokuhaku Jikkou Iinkai: Renai Series (music and animation series featuring seiyuus) created by HoneyWorks getting an animated movie to premiere Spring 2016.\\r\\n\\r\\n',\n",
       " 'Current/Latest Season': 'Season 1',\n",
       " 'URL': 'https://www4.animeseries.io/anime/zutto-mae-kara-suki-deshita-kokuhaku-jikkou-iinkai-movie.html',\n",
       " 'Status': 'Completed',\n",
       " 'Initial Air Date': '2016',\n",
       " 'Genre': 'Romance, School',\n",
       " 'Episodes Aired': '1',\n",
       " 'Series/Movie': 'Movie',\n",
       " 'Sub/Dub': 'Sub'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anime_dict #visualizing the data structure of the item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Anime Till Date: 7490\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Number of Anime Till Date:\",len(Anime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Anime Title': '?Maria-sama ga Miteru Haru ',\n",
       " 'Description': 'Life goes on for the ladies in the Yamayurikai. On the one-year anniversary of Sachiko and Yumi becoming sisters, Yumi receives a difficult task from Sachiko: to finally acknowledge someone as her younger sister.\\r\\n\\xa0',\n",
       " 'Current/Latest Season': '2nd',\n",
       " 'URL': 'https://www4.animeseries.io/anime/-maria-sama-ga-miteru-haru-2nd.html',\n",
       " 'Status': 'Completed',\n",
       " 'Initial Air Date': '2006',\n",
       " 'Genre': 'Drama, School, Shounen Ai, Slice of Life',\n",
       " 'Episodes Aired': '13',\n",
       " 'Series/Movie': 'Series',\n",
       " 'Sub/Dub': 'Sub'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Anime[0] #viewing the first item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file saved to:  C:\\Users\\Tejas\\DataScience\\Anime_Data_Base.csv\n"
     ]
    }
   ],
   "source": [
    "#Initilizing the header file\n",
    "header = ['Anime Title', 'Description', 'Current/Latest Season', 'Episodes Aired', 'Status', 'Initial Air Date', 'Genre', 'Sub/Dub', 'Series/Movie', 'URL']\n",
    "\n",
    "#Writing the collected data into readable format i.e, .csv file\n",
    "with open(r'C:\\Users\\Tejas\\DataScience\\Anime_Data_Base_v01.csv', 'w+', newline='', encoding=\"utf-8\") as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=header)\n",
    "\n",
    "    writer.writeheader()\n",
    "    writer.writerows(Anime)\n",
    "    \n",
    "print(\"CSV file saved to: \",r'C:\\Users\\Tejas\\DataScience\\Anime_Data_Base.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
